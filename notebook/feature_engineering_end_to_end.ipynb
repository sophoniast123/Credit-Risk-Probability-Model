{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16341e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# WoE library\n",
    "from xverse.transformer import WOE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1937be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ZAK-TECH\\Desktop\\KAIM_week4\\data\\raw\\data (1).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459519e",
   "metadata": {},
   "source": [
    "\n",
    "2.1 Aggregate Features per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bef1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerAggregateFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, customer_col=\"CustomerId\", amount_col=\"Amount\"):\n",
    "        self.customer_col = customer_col\n",
    "        self.amount_col = amount_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        agg = X.groupby(self.customer_col)[self.amount_col].agg(\n",
    "            TotalTransactionAmount=\"sum\",\n",
    "            AverageTransactionAmount=\"mean\",\n",
    "            TransactionCount=\"count\",\n",
    "            StdTransactionAmount=\"std\"\n",
    "        ).reset_index()\n",
    "        return X.merge(agg, on=self.customer_col, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3800ef",
   "metadata": {},
   "source": [
    "2.2 Date-Time Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d155c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, datetime_col=\"TransactionStartTime\"):\n",
    "        self.datetime_col = datetime_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "        X[\"TransactionHour\"] = X[self.datetime_col].dt.hour\n",
    "        X[\"TransactionDay\"] = X[self.datetime_col].dt.day\n",
    "        X[\"TransactionMonth\"] = X[self.datetime_col].dt.month\n",
    "        X[\"TransactionYear\"] = X[self.datetime_col].dt.year\n",
    "        return X.drop(columns=[self.datetime_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217cac5",
   "metadata": {},
   "source": [
    "feature lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90a699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"Amount\", \"Value\", \"TransactionHour\", \"TransactionDay\",\n",
    "    \"TransactionMonth\", \"TransactionYear\",\n",
    "    \"TotalTransactionAmount\", \"AverageTransactionAmount\",\n",
    "    \"TransactionCount\", \"StdTransactionAmount\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"CurrencyCode\", \"CountryCode\", \"ProviderId\", \"ProductId\",\n",
    "    \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f37f8",
   "metadata": {},
   "source": [
    "Numeric & Categorical Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fac7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())  # Standardization\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f268725",
   "metadata": {},
   "source": [
    "Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb751ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bfbe2",
   "metadata": {},
   "source": [
    "Full End-to-End Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6ddc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    (\"aggregate_features\", CustomerAggregateFeatures()),\n",
    "    (\"datetime_features\", DateTimeFeatureExtractor()),\n",
    "    (\"preprocessor\", preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419002ac",
   "metadata": {},
   "source": [
    "apply pipeline to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6201bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=[\"FraudResult\"])\n",
    "y = df[\"FraudResult\"]\n",
    "\n",
    "# Transform features\n",
    "X_transformed = full_pipeline.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441f59b",
   "metadata": {},
   "source": [
    "woe and iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e6244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import WoEEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d88ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZAK-TECH\\AppData\\Local\\Temp\\ipykernel_4340\\2948754614.py:92: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df_tmp.groupby(\"feature\")[\"target\"]\n",
      "C:\\Users\\ZAK-TECH\\AppData\\Local\\Temp\\ipykernel_4340\\2948754614.py:92: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df_tmp.groupby(\"feature\")[\"target\"]\n",
      "C:\\Users\\ZAK-TECH\\AppData\\Local\\Temp\\ipykernel_4340\\2948754614.py:92: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df_tmp.groupby(\"feature\")[\"target\"]\n",
      "C:\\Users\\ZAK-TECH\\AppData\\Local\\Temp\\ipykernel_4340\\2948754614.py:114: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df_tmp.groupby(\"feature\")[\"target\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information Value (IV) (Filtered, IV >= 0.02):\n",
      "          variable        IV\n",
      "1        Value_bin  2.920896\n",
      "0       Amount_bin  2.516343\n",
      "8        ChannelId  1.154068\n",
      "7  ProductCategory  0.821602\n",
      "9  PricingStrategy  0.546647\n",
      "3     TxnDayOfWeek  0.140917\n",
      "2      TxnHour_bin  0.073065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DROP ID COLUMNS\n",
    "\n",
    "id_cols = [\n",
    "    \"TransactionId\", \"BatchId\", \"AccountId\",\n",
    "    \"SubscriptionId\", \"CustomerId\",\n",
    "    \"ProviderId\", \"ProductId\"\n",
    "]\n",
    "\n",
    "df_model = df.drop(columns=id_cols)\n",
    "\n",
    "\n",
    "# HANDLE TIME FEATURE\n",
    "\n",
    "df_model[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    df_model[\"TransactionStartTime\"]\n",
    ")\n",
    "\n",
    "df_model[\"TxnHour\"] = df_model[\"TransactionStartTime\"].dt.hour\n",
    "df_model[\"TxnDayOfWeek\"] = df_model[\"TransactionStartTime\"].dt.dayofweek\n",
    "df_model[\"IsWeekend\"] = df_model[\"TxnDayOfWeek\"].isin([5, 6]).astype(int)\n",
    "\n",
    "df_model[\"TxnHour_bin\"] = pd.cut(\n",
    "    df_model[\"TxnHour\"],\n",
    "    bins=[-1, 5, 11, 17, 23],\n",
    "    labels=[\"Night\", \"Morning\", \"Afternoon\", \"Evening\"]\n",
    ")\n",
    "\n",
    "\n",
    "# BIN NUMERIC FEATURES (SAFE)\n",
    "\n",
    "df_model[\"Amount_bin\"] = pd.qcut(\n",
    "    df_model[\"Amount\"], q=2, duplicates=\"drop\"\n",
    ")\n",
    "df_model[\"Value_bin\"] = pd.qcut(\n",
    "    df_model[\"Value\"], q=2, duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "# CLEAN CATEGORICAL FEATURES\n",
    "\n",
    "cat_cols = [\n",
    "    \"CurrencyCode\",\n",
    "    \"CountryCode\",\n",
    "    \"ProductCategory\",\n",
    "    \"ChannelId\",\n",
    "    \"PricingStrategy\"\n",
    "]\n",
    "\n",
    "df_model[cat_cols] = df_model[cat_cols].fillna(\"Missing\")\n",
    "\n",
    "# Merge rare categories (>3%)\n",
    "threshold = int(0.03 * len(df_model))\n",
    "for col in cat_cols:\n",
    "    freq = df_model[col].value_counts()\n",
    "    rare = freq[freq < threshold].index\n",
    "    df_model[col] = df_model[col].replace(rare, \"Other\")\n",
    "\n",
    "\n",
    "# FINAL FEATURES\n",
    "\n",
    "features = [\n",
    "    \"Amount_bin\",\n",
    "    \"Value_bin\",\n",
    "    \"TxnHour_bin\",\n",
    "    \"TxnDayOfWeek\",\n",
    "    \"IsWeekend\",\n",
    "    \"CurrencyCode\",\n",
    "    \"CountryCode\",\n",
    "    \"ProductCategory\",\n",
    "    \"ChannelId\",\n",
    "    \"PricingStrategy\"\n",
    "]\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model[\"FraudResult\"]\n",
    "\n",
    "# Treat numeric features that are categorical\n",
    "X[\"TxnDayOfWeek\"] = X[\"TxnDayOfWeek\"].astype(str)\n",
    "\n",
    "\n",
    "# MANUAL WoE CALCULATION (VERSION-SAFE)\n",
    "\n",
    "def manual_woe(X, y, epsilon=1e-6):\n",
    "    X_woe = pd.DataFrame(index=X.index)\n",
    "    for col in X.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "        df_tmp = pd.DataFrame({\"feature\": X[col], \"target\": y})\n",
    "        grouped = df_tmp.groupby(\"feature\")[\"target\"]\n",
    "\n",
    "        good = grouped.apply(lambda x: (x == 0).sum())\n",
    "        bad = grouped.apply(lambda x: (x == 1).sum())\n",
    "\n",
    "        good_dist = (good + epsilon) / (good.sum() + epsilon*len(good))\n",
    "        bad_dist = (bad + epsilon) / (bad.sum() + epsilon*len(bad))\n",
    "\n",
    "        woe_map = np.log(bad_dist / good_dist)\n",
    "        X_woe[col] = X[col].map(woe_map)\n",
    "\n",
    "    return X_woe\n",
    "\n",
    "X_woe = manual_woe(X, y)\n",
    "\n",
    "\n",
    "# IV CALCULATION (SAFE)\n",
    "\n",
    "def calculate_iv(X, y):\n",
    "    iv_dict = {}\n",
    "    for col in X.columns:\n",
    "        df_tmp = pd.DataFrame({\"feature\": X[col], \"target\": y})\n",
    "        grouped = df_tmp.groupby(\"feature\")[\"target\"]\n",
    "\n",
    "        good = grouped.apply(lambda x: (x == 0).sum())\n",
    "        bad = grouped.apply(lambda x: (x == 1).sum())\n",
    "\n",
    "        good_dist = (good + 1e-6) / (good.sum() + 1e-6*len(good))\n",
    "        bad_dist = (bad + 1e-6) / (bad.sum() + 1e-6*len(bad))\n",
    "\n",
    "        woe_vals = np.log(bad_dist / good_dist)\n",
    "        iv = ((bad_dist - good_dist) * woe_vals).sum()\n",
    "\n",
    "        iv_dict[col] = iv\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        iv_dict.items(),\n",
    "        columns=[\"variable\", \"IV\"]\n",
    "    ).sort_values(\"IV\", ascending=False)\n",
    "\n",
    "iv_df = calculate_iv(X, y)\n",
    "\n",
    "\n",
    "# FILTER LOW-IV FEATURES\n",
    "\n",
    "iv_threshold = 0.02\n",
    "iv_df_filtered = iv_df[iv_df[\"IV\"] >= iv_threshold]\n",
    "\n",
    "print(\"\\nInformation Value (IV) (Filtered, IV >= 0.02):\")\n",
    "print(iv_df_filtered)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1beba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
